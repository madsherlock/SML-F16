\chapter{k-NN}
K - nearest - neighbor or k-NN,
is a method for classifying observations based on the similarities
to features extracted from training data.
The idea in k-NN is to identiy the k observations which are closest (most similar) to the
observation to be classified, each observation voting for its class
(either with a 1, or using a distance metric).
 The class with the most votes determines which class the new observation
will be classified as. 
k is chosen by the user,
 and has an effect of the peformance of the algorithm. 
k-NN has an optimal classification rate on training data when k becomes very large, 
but will computation wise take more time and vice versa.
For testing data that is not part of the training data,
the optimal classification rate is typically found at a different k.
This motivates the study of k vs. classification rate.